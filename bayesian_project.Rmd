---
title: "Bayesian modeling and prediction for movies"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
    css: style.css
---

### Load packages

```{r diagplot, echo=FALSE, cache=T}
require(ggplot2)
diagPlot<-function(model){
    p1<-ggplot(model, aes(.fitted, .resid))+geom_point()
    p1<-p1+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")
    p1<-p1+xlab("Fitted values")+ylab("Residuals")
    p1<-p1+ggtitle("Residual vs Fitted Plot")+theme_bw()
    
    p2<-ggplot(model, aes(qqnorm(.stdresid)[[1]], .stdresid))+geom_point(na.rm = TRUE)
    p2<-p2+geom_abline(aes(qqline(.stdresid)))+xlab("Theoretical Quantiles")+ylab("Standardized Residuals")
    p2<-p2+ggtitle("Normal Q-Q")+theme_bw()
    
    p3<-ggplot(model, aes(.fitted, sqrt(abs(.stdresid))))+geom_point(na.rm=TRUE)
    p3<-p3+stat_smooth(method="loess", na.rm = TRUE)+xlab("Fitted Value")
    p3<-p3+ylab(expression(sqrt("|Standardized residuals|")))
    p3<-p3+ggtitle("Scale-Location")+theme_bw()
    
    p4<-ggplot(model, aes(seq_along(.cooksd), .cooksd))+geom_bar(stat="identity", position="identity")
    p4<-p4+xlab("Obs. Number")+ylab("Cook's distance")
    p4<-p4+ggtitle("Cook's distance")+theme_bw()
    
    p5<-ggplot(model, aes(.hat, .stdresid))+geom_point(aes(size=.cooksd), na.rm=TRUE)
    p5<-p5+stat_smooth(method="loess", na.rm=TRUE)
    p5<-p5+xlab("Leverage")+ylab("Standardized Residuals")
    p5<-p5+ggtitle("Residual vs Leverage Plot")
    p5<-p5+scale_size_continuous("Cook's Distance", range=c(1,5))
    p5<-p5+theme_bw()+theme(legend.position="bottom")
    
    p6<-ggplot(model, aes(.hat, .cooksd))+geom_point(na.rm=TRUE)+stat_smooth(method="loess", na.rm=TRUE)
    p6<-p6+xlab("Leverage hii")+ylab("Cook's Distance")
    p6<-p6+ggtitle("Cook's dist vs Leverage hii/(1-hii)")
    p6<-p6+geom_abline(slope=seq(0,3,0.5), color="gray", linetype="dashed")
    p6<-p6+theme_bw()
    
    return(list(rvfPlot=p1, qqPlot=p2, sclLocPlot=p3, cdPlot=p4, rvlevPlot=p5, cvlPlot=p6))
}
```

```{r multiplot, echo=FALSE, cache=T}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
library(BAS)
library(grid)
library(gridExtra)
suppressMessages(library(GGally))
```

### Load data

```{r load-data}
setwd("~/coursera/bayesian")
load("movies.Rdata")
```
## Part 1: Data
The data set is comprised of `r nrow(movies)` randomly sampled movies produced and released before 2016. The data comes from
Rotten Tomatoes and IMDb. Additionally there are further descriptive variables like actors, directors and 
release dates. The data is not a complete list of movies released before 2016. Its only a subset taken form
the full data set. There is no information provided regarding the sampling method used to obtain the set.

For this analysis it is assumed that the observations are independent and evenly distributed. The count of the
movies of 651 is far  below the 10% of the population threshold for independence. Even the ggplot2 movies
data set has ~30000 observations about movies. The sample was obtained randomly from existing data, so one can generalize
to the population as a whole but we cannot infer causality since this is a observational study.

Some of these variables are only there for informational purposes and do not make any sense to include in a 
statistical analysis. Based on the research question one will omit certain observations or restructure some
of the variables to make them suitable for answering.

## Part 2: Data manipulation
For the analysis lets create some categorical variables to assist us in exploring the data.
```{r manip}


movies <- movies %>% 
          mutate(feature_film=as.factor(ifelse(title_type == 'Feature Film', 'yes', 'no'))) %>%
          mutate(drama=as.factor(ifelse(genre == 'Drama', 'yes', 'no'))) %>%
          mutate(mpaa_rating_R=as.factor(ifelse(mpaa_rating == 'R', 'yes', 'no'))) %>%
          mutate(oscar_season=as.factor(ifelse(thtr_rel_month %in% c(10:12), 'yes', 'no'))) %>%
          mutate(summer_season=as.factor(ifelse(thtr_rel_month %in% c(5:8), 'yes', 'no')))
```
Now extract only the needed variables for modelling.
```{r extract}
m <- subset(movies, select = c(
               audience_score, feature_film, drama, runtime, mpaa_rating_R, thtr_rel_year, oscar_season, summer_season, imdb_rating, 
              imdb_num_votes, critics_score, best_pic_nom, best_pic_win, best_actor_win, best_actress_win, best_dir_win, top200_box
                ))
```
Examine if there are NA's and omit them in the analysis.
```{r na}
M <- sapply(m, function(x) sum(is.na(x))); M[M>0]
```
There is one observation where the runtime is not available, filter the NA and update the data set.
```{r omit}
m <- filter(m, !is.na(runtime))
```

## Part 3: Exploratory data analysis

First focus on the categorical variables and print the corresponding boxplots, to see we can see a pattern in first place.
```{r anal, fig.width=10, fig.height= 15, cache=TRUE, echo=FALSE}
p0 <- ggplot(m,aes(x=feature_film,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p0 <- p0 + geom_boxplot(aes(fill=feature_film)) + ggtitle("Score: Feature Film") + xlab("Feature Film") + ylab("Audience Score") + theme(legend.position="none")

p1 <- ggplot(m,aes(x=drama,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p1 <- p1 + geom_boxplot(aes(fill=drama)) + ggtitle("Score vs Drama") + xlab("Genre Drama") + ylab("") + theme(legend.position="none")

p2 <- ggplot(m,aes(x=mpaa_rating_R,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p2 <- p2 + geom_boxplot(aes(fill=mpaa_rating_R)) + ggtitle("Score vs MPAA") + xlab("MPAA") + ylab("") + theme(legend.position="none")

p3 <- ggplot(m,aes(x=oscar_season,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p3 <- p3 + geom_boxplot(aes(fill=oscar_season)) + ggtitle("Score vs Oscar") + xlab("Oscar Season") + ylab("") + theme(legend.position="none")

p4 <- ggplot(m,aes(x=summer_season,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p4 <- p4 + geom_boxplot(aes(fill=summer_season)) + ggtitle("Score vs Summer") + xlab("Summer Season") + ylab("")  + theme(legend.position="none")

p5 <- ggplot(m,aes(x=best_pic_nom,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p5 <- p5 + geom_boxplot(aes(fill=best_pic_nom)) + ggtitle("Score vs Best Nom") + xlab("Best Pic Nom") + ylab("")  + theme(legend.position="none")

p6 <- ggplot(m,aes(x=best_actor_win,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p6 <- p6 + geom_boxplot(aes(fill=best_actor_win)) + ggtitle("Score vs Best Act") + xlab("Best Actor Win") + ylab("")  + theme(legend.position="none")

p7 <- ggplot(m,aes(x=best_pic_win,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p7 <- p7 + geom_boxplot(aes(fill=best_pic_win)) + ggtitle("Score vs Best Win") + xlab("Best Pic Win") + ylab("")  + theme(legend.position="none")

p8 <- ggplot(m,aes(x=best_actress_win,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p8 <- p8 + geom_boxplot(aes(fill=best_actress_win)) + ggtitle("Score vs Best Acs") + xlab("Best Actress Win") + ylab("")  + theme(legend.position="none")

p9 <- ggplot(m,aes(x=best_dir_win,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p9 <- p9 + geom_boxplot(aes(fill=best_dir_win)) + ggtitle("Score vs Best Dir") + xlab("Best Dir Win") + ylab("")  + theme(legend.position="none")

p10 <- ggplot(m,aes(x=top200_box,y=audience_score)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
p10 <- p10 + geom_boxplot(aes(fill=top200_box)) + ggtitle("Score vs Top200") + xlab("Top200 Box") + ylab("")  + theme(legend.position="none")


multiplot(p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, cols = 3)

```

It looks like that there are 4 variables that have an "impact" on the audience_score at first sight. Namely: feature_film, best_pic_nom, 
top200_box and best_pic_win. These circumstances will be further examined at the modelling phase. Lets check the numerical variables left. 
First check for collinearity.
```{r corr, fig.width=10,fig.height=10, cache=TRUE}
ggpairs(m, columns = c(1,4,6,9,10,11) )
```
The imdb_rating is highly correlated r=0.865 with the audience_score. Collinearity can change the coefficient estimates 
erratically in response to small changes in the model or the data. Remove imdb_rating from the data set. Another common
way to check for collinearity is with variance infalction factors ('vif' function in 'car'). Applying 'vif' to the 
model gives 'aliased coefficients' which means that variables are collinear.

```{r rem}
m <- subset(m, select = -c(imdb_rating))
```

Now plot the audience_score against thtr_rel_year since it has the lowest correlation and color piecewise runtime,
imdb_num_votes and critics_score to see one can register a color pattern. 

```{r numerical, fig.width=10, echo=FALSE, cache=TRUE}
n0 <- ggplot(m, aes(x=thtr_rel_year, y=audience_score))
n0 <- n0 + geom_point(aes(color=runtime)) + ggtitle("Score vs Runtime") + xlab("Rel Year") + ylab("Audience Score")

n1 <- ggplot(m, aes(x=thtr_rel_year, y=audience_score))
n1 <- n1 + geom_point(aes(color=imdb_num_votes)) + ggtitle("Score vs #IMBD") + xlab("Rel Year") + ylab("Audience Score")

n2 <- ggplot(m, aes(x=thtr_rel_year, y=audience_score))
n2 <- n2 + geom_point(aes(color=critics_score)) + ggtitle("Score vs Critics") + xlab("Rel Year") + ylab("Audience Score")

multiplot(n0, n1, n2, cols = 2)
```

The only pattern visible is for 'critics_score' most of the time when 'critics_score' rises the 'audience_score' rises too, 
which is also evident in the correlation factor of 0.7. Checking with 'vif' there are no more aliased coefficients and
thats why we leave 'critics_score' as a describing variable for the model.

## Part 4: Modeling
```{r bas, cache=T}
bm <- bas.lm(audience_score ~ ., data=m, method='MCMC',
             prior='ZS-null', 
             modelprior=uniform(), initprobs="eplogp")
```

```{r diag, cache=T}
diagnostics(bm, type="model",  pch=16)
```

The two estimators are in pretty close agreement. The plot of the model probabilites suggests that one should use more MCMC.iterations 
if more accurate estimates of the posterior model probabilities are needed. Therefore set the iterations to MCMC.iterations=10^6 and 
check again.
```{r bas2, cache=T}
bm <- bas.lm(audience_score ~ ., data=m, method='MCMC',  MCMC.iterations = 10^6,
             prior='ZS-null', 
             modelprior=uniform(), initprobs="eplogp")
```

```{r diag2, cache=T}
diagnostics(bm, type="model",  pch=16)
```

The estimators are now more close to the line than before, 10^6 iterations for this model space is enough. Lets examine
the collection of models.
```{r mod, fig.width=10, fig.height=6}
image(bm, rotate=F)
```

According to the picture above the best model is the one including 'feature_film', 'drama', 'imdb_num_votes' and 'critics_score'. 
Additionally plot some graphical summaries of the output.
```{r basp, fig.height=6, fig.width=10}
par(mfrow=c(2,2))
plot(bm, ask=F)
```

The 'Residuals vs. Fitted' plot shows residuals centered around zero and almost constant variation. There are no outliers, so we can
assume that the model is doing pretty good.

The 'Model Probabilites' plot shows the cumulative probability of the models and is leveling off at 1000 number of samples and sampling
stops at 2000 samples as no additional models adds a increment to the cumulative probability.

The “Model Complexity” plot shows that the highest log marginal can be reached from 2 to 14 dimensions.

Last but not least the 'Inlucsion Probabilites' plot shows the marginal posterior inclusion probabilities (pip) for each of the 
covariates. As already seen in the model space plot, the variables for inclusion match

```{r coef, fig.width=10}
par(mfrow=c(1,4))
plot(coefficients(bm), ask=F)
```
The vertical bar represents the posterior probability that the coefficient is 0 while the bell shaped curve 
represents the density of plausible values from all the models where the coefficient is non-zero. Concluding
most of the coefficient can be excluded from the model excepting the coefficient mentioned above, which have
not vertical bar  and have a distribution with altitudes of almost 1.0. 



## Part 5: Prediction
For prediction the blockbuster movie Mad Max Fury Road will be used to test the model.
```{r pred}
madmax <- data.frame(
  audience_score=0,
  feature_film=factor("yes", levels=c("no", "yes")),
  drama=factor("no", levels=c("no", "yes")),
  runtime=120, 
  mpaa_rating_R=factor("yes", levels=c("no", "yes")),
  thtr_rel_year=2015,
  oscar_season=factor("yes", levels=c("no", "yes")),
  summer_season=factor("yes", levels=c("no", "yes")),
  imdb_num_votes=584601,
  critics_score=97, 
  best_pic_nom=factor("yes", levels=c("no", "yes")),
  best_pic_win=factor("no", levels=c("no", "yes")),
  best_actor_win=factor("no", levels=c("no", "yes")),
  best_actress_win=factor("no", levels=c("no", "yes")),
  best_dir_win=factor("no", levels=c("no", "yes")),
  top200_box=factor("yes", levels=c("no", "yes"))
)
p <- predict(bm, newdata=madmax, estimator="BMA", se.fit=TRUE)

p$fit
```
The predicted value is `r p$fit` in comparison to the true values of 84, the model predicted compared to the true value
with an error of 10.28%.


## Part 6: Conclusion

A linear regression model using bayesian model averaging was created which has some potential to predict the movie audience_score based
on the given coefficients. To improve the model more data is needed and the inclusion of maybe other coefficients that are not
included in this data set. The further improvement of this model goes beyond of the scope of this assignment.

